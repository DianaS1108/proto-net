{"cells":[{"cell_type":"markdown","metadata":{"id":"FjfEqn5ydCHN"},"source":["# Prep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96cKL41pdCHP"},"outputs":[],"source":["import torch\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import os\n","\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNyncTawdCHR"},"outputs":[],"source":["# for saving and reading results\n","\n","def save_list_to_file(list, path):\n","    with open(path, \"w\") as f:\n","        for item in list:\n","            f.write(f\"{item}\\n\")\n","\n","def read_file_to_list(path):\n","    with open(path, \"r\") as f:\n","        list = f.read().splitlines()\n","        list = [float(item) for item in list]\n","    return list"]},{"cell_type":"markdown","metadata":{"id":"BqC7ykexdCHS"},"source":["# Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sT71Gy32dCHT"},"outputs":[],"source":["data_dir = \"./data_omniglot\"  # change as need\n","\n","num_way_tr = 60\n","num_shot_tr = 5\n","num_query_tr = 5\n","\n","num_way_val = 20\n","num_shot_val = 5\n","num_query_val = 15\n","\n","# training\n","num_epoch = 100\n","num_iter = 100\n","\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Lh00DN_dCHU"},"outputs":[],"source":["# save results?\n","\n","save = False\n","\n","if save == True:\n","    output_dir = os.path.join(\".\", \"output\")"]},{"cell_type":"markdown","metadata":{"id":"gDTVmeHYdCHV"},"source":["# Data"]},{"cell_type":"markdown","metadata":{"id":"9D1r-qI4dCHV"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLXhkHmadCHW"},"outputs":[],"source":["def get_classes(path):\n","    with open(path) as f:\n","        classes = f.read().replace('/', os.sep).splitlines()\n","    return classes\n","\n","def get_class_label(classes):\n","    dic = {}\n","    for idx, c in enumerate(classes):\n","        dic[c] = idx\n","    return dic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gh3Q9Y3idCHY"},"outputs":[],"source":["from PIL import Image\n","from torchvision.transforms.functional import to_tensor\n","\n","def get_data(classes, class_label):\n","    x_list = []\n","    y_list = []\n","    for c in tqdm(classes, desc=\"Class\"):\n","        l = c.split(os.sep)\n","        path = os.path.join(data_dir, \"data\", l[0], l[1])\n","        rot = l[2][3:]\n","        for image in os.listdir(path):\n","            x = Image.open(os.path.join(path, image))\n","            x = x.rotate(float(rot))\n","            x = x.resize((28, 28))\n","            x = to_tensor(x)\n","            x_list.append(x)\n","            y_list.append(class_label[c])\n","    return x_list, y_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RWNEx6R3dCHY"},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class OmniglotDataset(Dataset):\n","    def __init__(self, mode):\n","        super().__init__()\n","        self.classes = get_classes(os.path.join(data_dir, \"splits\", \"vinyals\", mode + \".txt\"))\n","        self.class_label = get_class_label(self.classes)\n","        self.x, self.y = get_data(self.classes, self.class_label)\n","    \n","    def __getitem__(self, idx):\n","        return self.x[idx], self.y[idx]\n","\n","    def __len__(self):\n","        return len(self.y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkA_PbPydCHZ","outputId":"0fea4576-7f17-4443-a0df-ee9c3d8a5683"},"outputs":[],"source":["train_dataset = OmniglotDataset('train')\n","val_dataset = OmniglotDataset('val')\n","test_dataset = OmniglotDataset('test')"]},{"cell_type":"markdown","metadata":{"id":"E1jTrW7rdCHb"},"source":["## Sampler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vv0ua41pdCHc"},"outputs":[],"source":["def get_class_indices(labels, classes):\n","    dic = {}\n","    for c in tqdm(classes, desc=\"Class\"):\n","        dic[c] = np.where(labels == c)[0]\n","    return dic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y49jnm0MdCHc"},"outputs":[],"source":["class PrototypicalBatchSampler():\n","    def __init__(self, labels, num_way, num_samples, num_iter):\n","        super().__init__()\n","        self.num_way = num_way\n","        self.num_samples = num_samples\n","        self.num_iter = num_iter\n","\n","        self.classes = np.unique(labels)\n","        self.class_indices = get_class_indices(labels, self.classes)\n","\n","    \n","    def __iter__(self):\n","        for it in range(self.num_iter):\n","            batch = np.empty(self.num_way * self.num_samples, dtype=np.int64)\n","            \n","            # select classes\n","            c_idxs = torch.randperm(len(self.classes))[:self.num_way]\n","\n","            # select samples\n","            for i, c in enumerate(self.classes[c_idxs]):\n","                s_idxs = torch.randperm(len(self.class_indices[c]))[:self.num_samples]\n","\n","                sl = slice(i * self.num_samples, (i + 1) * self.num_samples)\n","                batch[sl] = self.class_indices[c][s_idxs]\n","                \n","            yield batch\n","\n","    def __len__(self):\n","        return self.num_iter"]},{"cell_type":"markdown","metadata":{"id":"nVJqLQVrdCHd"},"source":["## Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RSpalcetdCHe"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def get_dataloader(dataset, num_way, num_shot, num_query, num_iter):\n","    sampler = PrototypicalBatchSampler(dataset.y, num_way, num_shot + num_query, num_iter)\n","    return DataLoader(dataset, batch_sampler=sampler)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"igzBWzjtdCHf","outputId":"1d202341-8398-45b8-b9fd-6247e807a523"},"outputs":[],"source":["train_dataloader = get_dataloader(train_dataset, num_way_tr, num_shot_tr, num_query_tr, num_iter)\n","val_dataloader = get_dataloader(val_dataset, num_way_val, num_shot_val, num_query_val, num_iter)\n","test_dataloader = get_dataloader(test_dataset, num_way_val, num_shot_val, num_query_val, num_iter)\n","\n","# time taken for getting image indices for classes when constructing sampler"]},{"cell_type":"markdown","metadata":{"id":"Qb4tlIYDdCHg"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RvnFFOsPdCHg"},"outputs":[],"source":["import torch.nn as nn\n","\n","def conv_block(in_channels, out_channels):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2)\n","    )\n","\n","class ProtoNet(nn.Module):\n","    def __init__(self, x_dim=1, hid_dim=64, z_dim=64):\n","        super(ProtoNet, self).__init__()\n","        self.encoder = nn.Sequential(\n","            conv_block(x_dim, hid_dim),\n","            conv_block(hid_dim, hid_dim),\n","            conv_block(hid_dim, hid_dim),\n","            conv_block(hid_dim, z_dim),\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        return x.view(x.size(0), -1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gpvHjsE5dCHh"},"outputs":[],"source":["# instantiate\n","model = ProtoNet().to(device)"]},{"cell_type":"markdown","metadata":{"id":"faweCE-KdCHh"},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JJggPQQdCHh"},"outputs":[],"source":["def compute_dist_matrix(x, y):\n","    # x: n x d\n","    # y: m x d\n","    n = x.shape[0]\n","    m = y.shape[0]\n","    d = x.shape[1]\n","\n","    x = x.unsqueeze(1).expand(n, m, d)\n","    y = y.unsqueeze(0).expand(n, m, d)\n","\n","    return torch.pow(x - y, 2).sum(2)  # n x m"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGu1us0ddCHh"},"outputs":[],"source":["from torch.nn.functional import log_softmax\n","\n","def compute_loss_acc(output, target, num_shot):\n","    classes = torch.unique(target)\n","    \n","    for i, c in enumerate(classes):\n","        c_idxs = torch.where(target == c)[0]\n","        c_support_idxs = c_idxs[:num_shot]\n","        c_query_idxs = c_idxs[num_shot:]\n","\n","        c_prototype = output[c_support_idxs].mean(0)\n","        c_query = output[c_query_idxs]\n","        c_target_idxs = torch.ones(len(c_query), dtype=torch.int64) * i\n","        c_target_idxs = c_target_idxs.to(device)\n","\n","        if i == 0:\n","            prototypes = c_prototype\n","            query = c_query\n","            target_idxs = c_target_idxs\n","        else:\n","            prototypes = torch.vstack((prototypes, c_prototype))\n","            query = torch.vstack((query, c_query))\n","            target_idxs = torch.hstack((target_idxs, c_target_idxs))\n","        \n","    dists = compute_dist_matrix(prototypes, query)\n","    log_prob = log_softmax(-dists, dim=0)\n","\n","    target_matrix = torch.zeros_like(log_prob)\n","    target_matrix[(target_idxs, torch.arange(len(query)))] = torch.ones(len(query)).to(device)\n","\n","    loss = (-log_prob * target_matrix).mean()\n","\n","    pred = torch.max(log_prob, dim=0).indices\n","    acc = (target_idxs == pred).float().mean()\n","\n","    return loss, acc"]},{"cell_type":"markdown","metadata":{"id":"EO3880PDdCHi"},"source":["# Optimiser"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhGtXOjfdCHi"},"outputs":[],"source":["from torch.optim import Adam\n","from torch.optim.lr_scheduler import StepLR\n","\n","lr = 0.001\n","scheduler_step = 20\n","scheduler_gamma = 0.5\n","\n","optimiser = Adam(model.parameters(), lr=lr)\n","scheduler = StepLR(optimizer=optimiser, gamma=scheduler_gamma, step_size=scheduler_step)"]},{"cell_type":"markdown","metadata":{"id":"BE8EYY6IdCHj"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5Vz_NQ_dCHk"},"outputs":[],"source":["# Initialise training hisotry container\n","\n","history = {\n","    \"total_epoch\": 0,\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"val_loss\": [],\n","    \"val_acc\": [],\n","    \"best_acc\": 0,\n","    \"best_epoch\": None,\n","    \"best_model\": None\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q39UoEF0dCHl"},"outputs":[],"source":["def train(epoch):\n","    global history\n","\n","    for ep in range(epoch):\n","        history[\"total_epoch\"] += 1\n","\n","        # train\n","        model.train()\n","        sum_loss = 0\n","        sum_acc = 0\n","        for x, y in train_dataloader:\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            loss, acc = compute_loss_acc(output, y, num_shot_tr)\n","\n","            optimiser.zero_grad()\n","            loss.backward()\n","            optimiser.step()\n","\n","            sum_loss += loss.item()\n","            sum_acc += acc.item()\n","        \n","        scheduler.step()\n","    \n","        avg_loss = sum_loss / num_iter\n","        avg_acc = sum_acc / num_iter\n","        history[\"train_loss\"].append(avg_loss)\n","        history[\"train_acc\"].append(avg_acc)\n","\n","        # validation\n","        model.eval()\n","        sum_loss = 0\n","        sum_acc = 0\n","        for x,y in val_dataloader:\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            loss, acc = compute_loss_acc(output, y, num_shot_val)\n","\n","            sum_loss += loss.item()\n","            sum_acc += acc.item()\n","        \n","        avg_loss = sum_loss / num_iter\n","        avg_acc = sum_acc / num_iter\n","        history[\"val_loss\"].append(avg_loss)\n","        history[\"val_acc\"].append(avg_acc)\n","\n","        if avg_acc > history[\"best_acc\"]:\n","            history[\"best_acc\"] = avg_acc\n","            history[\"best_epoch\"] = history[\"total_epoch\"]\n","            history[\"best_model\"] = model.state_dict()\n","        \n","        print(f\"Epoch {history['total_epoch']}: Train Loss {history['train_loss'][-1]}, Acc {history['train_acc'][-1]}; Val Loss {history['val_loss'][-1]}, Acc {history['val_acc'][-1]}; Best {history['best_acc']} (Epoch {history['best_epoch']})\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuEE2jIydCHm","outputId":"5fe30abf-8224-45f6-ca16-a01979d9c7cd"},"outputs":[],"source":["train(num_epoch)\n","\n","# num_episode = num_epoch * num_iter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16Ch420HdCHm"},"outputs":[],"source":["# Save results\n","\n","if save:\n","    \n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    # last model\n","    torch.save(\n","        model.state_dict(),\n","        os.path.join(output_dir, 'last_model.pth')\n","        )\n","\n","    # best model\n","    torch.save(\n","        history[\"best_model\"],\n","        os.path.join(output_dir, 'best_model.pth')\n","        )\n","\n","    for name in ['train_loss', 'train_acc', 'val_loss', 'val_acc']:\n","        save_list_to_file(\n","            history[name],\n","            os.path.join(output_dir, name + '.txt')\n","            )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZMghqsodCHn","outputId":"fbee52bc-786b-4e52-cf7e-71c742ec08c5"},"outputs":[],"source":["# Plot training curve\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n","\n","ax1.plot(history[\"train_loss\"], label='train')\n","ax1.plot(history[\"val_loss\"], label='val')\n","ax1.grid()\n","ax1.legend()\n","ax1.set_xlabel('Epoch')\n","ax1.set_title('Loss')\n","\n","ax2.plot(history[\"train_acc\"], label='train')\n","ax2.plot(history[\"val_acc\"], label='val')\n","ax2.grid()\n","ax2.legend()\n","ax2.set_xlabel('Epoch')\n","ax2.set_title('Acc')"]},{"cell_type":"markdown","metadata":{"id":"1xGk8hp2dCHn"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXohz2GQdCHo"},"outputs":[],"source":["def test(model, epoch):\n","    avg_acc = []\n","    model.eval()\n","    for ep in tqdm(range(epoch)):\n","        for x, y in test_dataloader:\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            _, acc = compute_loss_acc(output, y, num_shot_val)\n","            avg_acc.append(acc.item())\n","    avg_acc = np.mean(avg_acc)\n","    print(f\"Test Acc: {avg_acc}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUuenoxQdCHo","outputId":"c7c9894f-0e67-4e5e-ff1f-2f38259f8497"},"outputs":[],"source":["test(model, 10)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"prototypical","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d1505ef461b1b5e570209a43b042524dcff6d4158b00058e702925339e16e60e"}}},"nbformat":4,"nbformat_minor":0}
